{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mptchs\n",
    "import _pickle as pickle\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import colors as mcolors\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "dir = r'C:\\Jypiter\\Данные.csv' # указываем путь к файлу с данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [] # массив цветов для последующих графиков\n",
    "for i in mcolors.CSS4_COLORS:\n",
    "    colors.append(mcolors.CSS4_COLORS[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = ['X'+str(i) for i in range(1, 49)]\n",
    "\n",
    "types = {'Название': str} # указание типов для чтения из csv\n",
    "for i in dtype:\n",
    "    types[i] = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xcd in position 0: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c159d7002451>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcsv_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Jypiter\\Data_for_neural_klast.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xcd in position 0: invalid continuation byte"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xc4 in position 11: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-4572ce81d098>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcsv_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"C:\\Jypiter\\Данные.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_bad_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# читаем данные из файла\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\genericpath.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;34m\"\"\"Test whether a path exists.  Returns False for broken symbolic links\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc4 in position 11: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "csv_data = pd.read_csv(dir, decimal=',', sep=';', encoding='utf-8', dtype=types) # читаем данные из файла"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data = csv_data.as_matrix() # приводим к numpy-массиву\n",
    "names = csv_data[:,0] # обрезаем названия. далее используем как псевдометки класса, чтобы раскрашивались разными цветами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = csv_data[:, (1, 3)] # выбираем X1 - X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = normalize(data) # нормализуем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def man_dist_pbc(m, vector, shape=(10, 10)):\n",
    "    \"\"\" Manhattan distance calculation of coordinates with periodic boundary condition\n",
    "    :param m: {numpy.ndarray} array / matrix\n",
    "    :param vector: {numpy.ndarray} array / vector\n",
    "    :param shape: {tuple} shape of the SOM\n",
    "    :return: {numpy.ndarray} Manhattan distance for v to m\n",
    "    \"\"\"\n",
    "    dims = np.array(shape)\n",
    "    delta = np.abs(m - vector)\n",
    "    delta = np.where(delta > 0.5 * dims, np.abs(delta - dims), delta)\n",
    "    return np.sum(delta, axis=len(m.shape) - 1)\n",
    "\n",
    "\n",
    "class SOM(object):\n",
    "    def __init__(self, x, y, alpha=0.6, alpha_final=0.1, seed=42):\n",
    "        \"\"\" Initialize the SOM object with a given map size\n",
    "        \n",
    "        :param x: {int} width of the map\n",
    "        :param y: {int} height of the map\n",
    "        :param alpha: {float} initial alpha at training start\n",
    "        :param alpha_final: {float} final alpha to reach at last training epoch\n",
    "        :param seed: {int} random seed to use\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.shape = (x, y)\n",
    "        self.sigma = x / 2.\n",
    "        self.alpha = alpha\n",
    "        self.alpha_final = alpha_final\n",
    "        self.alpha_decay = float()\n",
    "        self.sigma_decay = float()\n",
    "        self.epoch = 0\n",
    "        self.map = np.array([])\n",
    "        self.indxmap = np.stack(\n",
    "            np.unravel_index(\n",
    "                np.arange(x * y, dtype=int).reshape(x, y), (x, y)\n",
    "            ), 2\n",
    "        )\n",
    "        print(\"Index map:\\n\", self.indxmap)\n",
    "        self.distmap = np.zeros((self.x, self.y))\n",
    "        self.pca = None  # attribute to save potential PCA to for saving and later reloading\n",
    "        self.inizialized = False\n",
    "        self.error = 0.  # reconstruction error\n",
    "        self.history = list()  # reconstruction error training history\n",
    "        # for debug\n",
    "        self.counter = 0\n",
    "\n",
    "    def winner(self, vector):\n",
    "        \"\"\" Compute the winner neuron closest to the vector (Euclidean distance)\n",
    "        \n",
    "        :param vector: {numpy.ndarray} vector of current data point(s)\n",
    "        :return: indices of winning neuron\n",
    "        \"\"\"\n",
    "        delta = np.abs(self.map - vector)\n",
    "        dists = np.sum(delta ** 2, axis=2)\n",
    "        indx = np.argmin(dists)\n",
    "        res = np.array([indx % self.x, indx // self.y])\n",
    "        self.counter += 1\n",
    "        return res\n",
    "\n",
    "    def cycle(self, vector):\n",
    "        \"\"\" Perform one iteration in adapting the SOM towards the chosen data point\n",
    "        \n",
    "        :param vector: {numpy.ndarray} current data point\n",
    "        \"\"\"\n",
    "        w = self.winner(vector)\n",
    "        # get Manhattan distance (with PBC) of every neuron in the map to the winner\n",
    "        dists = man_dist_pbc(self.indxmap, w, self.shape)\n",
    "\n",
    "        # smooth the distances with the current sigma\n",
    "        h = np.exp(-(dists / self.sigma) ** 2).reshape(self.x, self.y, 1)\n",
    "\n",
    "        # update neuron weights\n",
    "        self.map -= h * self.alpha * (self.map - vector)\n",
    "\n",
    "        print(\"Epoch %i;    Neuron [%i, %i];    \\tSigma: %.4f;    alpha: %.4f\" %\n",
    "              (self.epoch, w[0], w[1], self.sigma, self.alpha))\n",
    "\n",
    "        # update alpha, sigma and epoch\n",
    "        self.alpha = self.alpha * self.alpha_decay\n",
    "        self.sigma *= self.sigma_decay\n",
    "        self.epoch = self.epoch + 1\n",
    "\n",
    "    def initialize(self, data, how='pca'):\n",
    "        \"\"\" Initialize the SOM neurons\n",
    "        :param data: {numpy.ndarray} data to use for initialization\n",
    "        :param how: {str} how to initialize the map, available: 'pca' (via 4 first eigenvalues) or 'random' (via random\n",
    "            values normally distributed like data)\n",
    "        :return: initialized map in self.map\n",
    "        \"\"\"\n",
    "        self.map = np.random.normal(np.mean(data), np.std(data), size=(self.x, self.y, len(data[0])))\n",
    "        print(\"Before pca\")\n",
    "        print(self.map[0])\n",
    "        if how == 'pca':\n",
    "            eivalues = PCA(2).fit_transform(data.T).T\n",
    "            for i in range(2):\n",
    "                x = np.random.randint(0, self.x)\n",
    "                y = np.random.randint(0, self.y)\n",
    "                print(\"X, Y: \", x, y)\n",
    "                self.map[x, y] = eivalues[i]\n",
    "                print(\"Eigenvalues\", i, eivalues[i])\n",
    "        self.inizialized = True\n",
    "        print(\"After pca\")\n",
    "        print(self.map[0])\n",
    "\n",
    "    def fit(self, data, epochs, batch_size=1):\n",
    "        \"\"\" Train the SOM on the given data for several iterations\n",
    "        :param data: {numpy.ndarray} data to train on\n",
    "        :param epochs: {int} number of iterations to train\n",
    "        :param batch_size: {int} number of data points to consider per iteration\n",
    "        \"\"\"\n",
    "        if not self.inizialized:\n",
    "            self.initialize(data)\n",
    "\n",
    "        # get decays for given epochs\n",
    "        self.alpha_decay = (self.alpha_final / self.alpha) ** (1.0 / epochs)\n",
    "        self.sigma_decay = (np.sqrt(self.x) / (4. * self.sigma)) ** (1.0 / epochs)\n",
    "\n",
    "        samples = np.arange(len(data))\n",
    "        for i in range(epochs):\n",
    "            indx = np.random.choice(samples, batch_size)\n",
    "            self.cycle(data[indx])\n",
    "            if i % 1000 == 0:  # save the error to history every 1000 epochs\n",
    "                self.history.append(self.som_error(data))\n",
    "        self.error = self.som_error(data)\n",
    "\n",
    "    def transform(self, data):\n",
    "        \"\"\" Transform data in to the SOM space\n",
    "        :param data: {numpy.ndarray} data to be transformed\n",
    "        :return: transformed data in the SOM space\n",
    "        \"\"\"\n",
    "        m = self.map.reshape((self.x * self.y, self.map.shape[-1]))\n",
    "        dotprod = np.dot(np.exp(data), np.exp(m.T)) / np.sum(np.exp(m), axis=1)\n",
    "        return (dotprod / (np.exp(np.max(dotprod)) + 1e-8)).reshape(data.shape[0], self.x, self.y)\n",
    "\n",
    "    def distance_map(self, metric='euclidean'):\n",
    "        \"\"\" Get the distance map of the neuron weights. Every cell is the normalised sum of all distances between\n",
    "        the neuron and all other neurons.\n",
    "        Получение карты расстояний веслв нейронов. Каддая клетка представлена нормализованной суммой всех расстояний между данным нейроном\n",
    "        и другими нейронами.\n",
    "        :param metric: {str} distance metric to be used (see ``scipy.spatial.distance.cdist``)\n",
    "                        Какая метрика расстояния будет использована\n",
    "        :return: normalized sum of distances for every neuron to its neighbors\n",
    "                нормализованная сумма расстояний для каждого нейрона и его соседей\n",
    "        \"\"\"\n",
    "        dists = np.zeros((self.x, self.y))\n",
    "        for x in range(self.x):\n",
    "            for y in range(self.y):\n",
    "                d = cdist(self.map[x, y].reshape((1, -1)), \n",
    "                          self.map.reshape((-1, self.map.shape[-1])), \n",
    "                          metric=metric)\n",
    "                dists[x, y] = np.mean(d)\n",
    "        self.distmap = dists / float(np.max(dists))\n",
    "\n",
    "    def winner_map(self, data):\n",
    "        \"\"\" Get the number of times, a certain neuron in the trained SOM is winner for the given data.\n",
    "        :param data: {numpy.ndarray} data to compute the winner neurons on\n",
    "        :return: {numpy.ndarray} map with winner counts at corresponding neuron location\n",
    "        \"\"\"\n",
    "        wm = np.zeros(self.shape, dtype=int)\n",
    "        for d in data:\n",
    "            [x, y] = self.winner(d)\n",
    "            wm[x, y] += 1\n",
    "        return wm\n",
    "\n",
    "    def som_error(self, data):\n",
    "        \"\"\" Calculates the overall error as the average difference between the winning neurons and the data points\n",
    "        :param data: {numpy.ndarray}\n",
    "        :return: normalized error\n",
    "        \"\"\"\n",
    "        e = float()\n",
    "        for d in data:\n",
    "            [x, y] = self.winner(d)\n",
    "            dist = self.map[x, y] - d\n",
    "            e += np.sqrt(np.dot(dist, dist.T))\n",
    "        return e / float(len(data))\n",
    "\n",
    "    def plot_point_map(self, data, targets, targetnames, filename=None, colors=None, markers=None, density=True):\n",
    "        \"\"\" Visualize the som with all data as points around the neurons\n",
    "        Визуализирует данные как точки в клетках соответствующих нейронов\n",
    "        :param data: {numpy.ndarray} data to visualize with the SOM\n",
    "                                    данные, которые требуется визуализировать\n",
    "        :param targets: {list/array} array of target classes (0 to len(targetnames)) corresponding to data\n",
    "                                    массив знаечний классов, присвоенных образцам данных\n",
    "        :param targetnames: {list/array} names describing the target classes given in targets\n",
    "                                        наименования классов, использованных в targets\n",
    "        :param filename: {str} optional, if given, the plot is saved to this location\n",
    "                                        если указан - путь, куда будет сохранен рисунок\n",
    "        :param colors: {list/array} optional, if given, different classes are colored in these colors\n",
    "                                            если указано - цвета, которыми будут обознаечны различные классы\n",
    "        :param markers: {list/array} optional, if given, different classes are visualized with these markers\n",
    "                                            если указано - маркеры, которыми будут обозначены различные классы\n",
    "        :param density: {bool} whether to plot the density map with winner neuron counts in the background\n",
    "                            нужно ли строить карту плотности нейронов-победителей на заднем фоне\n",
    "        :return: plot shown or saved if a filename is given\n",
    "                показывает либо сохраняет рисунок по указанному пути\n",
    "        \"\"\"\n",
    "        print(\"\\nPlotting...\")\n",
    "        if not markers:\n",
    "            markers = ['o'] * len(targetnames)\n",
    "        if not colors:\n",
    "            colors = ['#EDB233', '#90C3EC', '#C02942', '#79BD9A', '#774F38', 'gray', 'black']\n",
    "        # Создание объектов Figure и Axex для дальнейшей работы с рисунком\n",
    "        if density:\n",
    "            fig, ax = self.plot_density_map(data, internal=True)\n",
    "        else:\n",
    "            # указываем размер холста в дюймах (высота и ширина карты берутся за основу)\n",
    "            fig, ax = plt.subplots(figsize=self.shape)\n",
    "\n",
    "        # Отрисовываем каждый образец(ряд) из переданных данных в виде точки на карте\n",
    "        for cnt, sample in enumerate(data):\n",
    "            plot_counter = cnt\n",
    "            w = self.winner(sample)\n",
    "            # Высчитываются координаты расположения точки с данными в клетке нейрона-победителя\n",
    "            # в некоторой окрестности вокруг середины клетки\n",
    "            y = w[0] + .5 + 0.1 * np.random.randn(1)\n",
    "            x = w[1] + .5 + 0.1 * np.random.randn(1)\n",
    "            \n",
    "            # Берем соответствующий маркер и цвет для отображения точки\n",
    "            marker = markers[targets[cnt]]\n",
    "            color = colors[targets[cnt]]\n",
    "            ax.plot(x,\n",
    "                    y,\n",
    "                    marker=marker, \n",
    "                    color=color, \n",
    "                    markersize=10)\n",
    "               \n",
    "\n",
    "        # устанавливаем равное соотношение сторон на графике        \n",
    "        ax.set_aspect('equal')\n",
    "        # устанавливаем максимальные значения координатной сетки в соостветствии с размерами карты\n",
    "        ax.set_xlim([0, self.x])\n",
    "        ax.set_ylim([0, self.y])\n",
    "        # Отрисовываем сетку на рисунке\n",
    "        ax.set_xticks(np.arange(self.x))\n",
    "        ax.set_yticks(np.arange(self.y))\n",
    "        ax.grid(which='major')\n",
    "\n",
    "        # Отрисовываем легенеду, а именно - наименования классов и их цвета\n",
    "        patches = [mptchs.Patch(color=colors[i], label=targetnames[i]) for i in range(len(targetnames))]\n",
    "        # Указываем то, как именно будет располагаться легенда - какике объекты Artist есть в качестве элементов легенды, \n",
    "        # в каких координатах будут отрисованы элементы и т. д.\n",
    "        legend = plt.legend(handles=patches, bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=len(targetnames),\n",
    "                            mode=\"expand\", borderaxespad=0.1)\n",
    "        legend.get_frame().set_facecolor('#e5e5e5')\n",
    "\n",
    "        if filename:\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "            print(\"Plot done!\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_density_map(self, data, colormap='Oranges', filename=None, internal=False):\n",
    "        \"\"\" Visualize the data density in different areas of the SOM.\n",
    "        :param data: {numpy.ndarray} data to visualize the SOM density (number of times a neuron was winner)\n",
    "                                    Данные, по которым визуализировать плотность SOM (по количеству раз которое каждый нейрон выигрывал)\n",
    "        :param colormap: {str} colormap to use, select from matplolib sequential colormaps\n",
    "                                Карта цветов, которую нужно использовать - берется из matplotlib\n",
    "        :param filename: {str} optional, if given, the plot is saved to this location\n",
    "                                Если указано - путь, куда будет сохранен рисунок\n",
    "        :param internal: {bool} if True, the current plot will stay open to be used for other plot functions\n",
    "                                Если значение True, то рисунок останется доступен для выполнения других операций над ним\n",
    "        :return: plot shown or saved if a filename is given\n",
    "        \"\"\"\n",
    "        # Получаем карту нейронов, в клетках которой - количество раз, которое определенный нейрон становился победителем\n",
    "        wm = self.winner_map(data)\n",
    "        fig, ax = plt.subplots(figsize=self.shape)\n",
    "        # Раскрашиваем клетки и добавляем шкалу цвета\n",
    "        plt.pcolormesh(wm, cmap=colormap, edgecolors=None)\n",
    "        plt.colorbar()\n",
    "        # Рисуем сетку на тот случай, если internal=True\n",
    "        plt.xticks(np.arange(self.x))\n",
    "        plt.yticks(np.arange(self.y))\n",
    "        ax.set_aspect('equal')\n",
    "        if not internal:\n",
    "            if filename:\n",
    "                plt.savefig(filename)\n",
    "                plt.close()\n",
    "                print(\"Plot done!\")\n",
    "            else:\n",
    "                plt.show()\n",
    "        else:\n",
    "            return fig, ax\n",
    "\n",
    "\n",
    "\n",
    "    def plot_distance_map(self, colormap='Oranges', filename=None):\n",
    "        \"\"\" Plot the distance map after training.\n",
    "        Рисует карту расстояний после обучения.\n",
    "        :param colormap: {str} colormap to use, select from matplolib sequential colormaps\n",
    "                            Карта цвета для использования\n",
    "        :param filename: {str} optional, if given, the plot is saved to this location\n",
    "                        Если указано - путь, куда будет сохранен рисунок\n",
    "        :return: plot shown or saved if a filename is given\n",
    "                Рисунок будет покзаан либо сохранен по указанному пути\n",
    "        \"\"\"\n",
    "        # Заполняем карту расстояний, если еще не заполнена\n",
    "        if np.mean(self.distmap) == 0.:\n",
    "            self.distance_map()\n",
    "        # Строим фигуру (холст), раскрашиваем его, добавляем шкалу цвета и рисуем сетку\n",
    "        fig, ax = plt.subplots(figsize=self.shape)\n",
    "        plt.pcolormesh(self.distmap, cmap=colormap, edgecolors=None)\n",
    "        plt.colorbar()\n",
    "        plt.xticks(np.arange(self.x))\n",
    "        plt.yticks(np.arange(self.y))\n",
    "        # Редактируем формат заголовка карты\n",
    "        plt.title(\"Distance Map\", fontweight='bold', fontsize=28)\n",
    "        ax.set_aspect('equal')\n",
    "        if filename:\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "            print(\"Plot done!\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_error_history(self, color='orange', filename=None):\n",
    "        \"\"\" plot the training reconstruction error history that was recorded during the fit\n",
    "        :param color: {str} color of the line\n",
    "        :param filename: {str} optional, if given, the plot is saved to this location\n",
    "        :return: plot shown or saved if a filename is given\n",
    "        \"\"\"\n",
    "        if not len(self.history):\n",
    "            raise LookupError(\"No error history was found! Is the SOM already trained?\")\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.plot(range(0, self.epoch, 1000), self.history, '-o', c=color)\n",
    "        ax.set_title('SOM Error History', fontweight='bold')\n",
    "        ax.set_xlabel('Epoch', fontweight='bold')\n",
    "        ax.set_ylabel('Error', fontweight='bold')\n",
    "        if filename:\n",
    "            plt.savefig(filename)\n",
    "            plt.close()\n",
    "            print(\"Plot done!\")\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\" Save the SOM instance to a pickle file.\n",
    "        :param filename: {str} filename (best to end with .p)\n",
    "        :return: saved instance in file with name ``filename``\n",
    "        \"\"\"\n",
    "        f = open(filename, 'wb')\n",
    "        pickle.dump(self.__dict__, f, 2)\n",
    "        f.close()\n",
    "\n",
    "    def load(self, filename):\n",
    "        \"\"\" Save the SOM instance to a pickle file.\n",
    "        :param filename: {str} filename (best to end with .p)\n",
    "        :return: saved instance in file with name ``filename``\n",
    "        \"\"\"\n",
    "        f = open(filename, 'rb')\n",
    "        tmp_dict = pickle.load(f)\n",
    "        f.close()\n",
    "        self.__dict__.update(tmp_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "som = SOM(2, 2)  # инициализируем SOM, 5x5\n",
    "som.fit(data, 1000)  # обучаем его 1000 эпох\n",
    "\n",
    "# create some dummy target values\n",
    "targets = [i for i in range(0, data.shape[0])] # создаем массив цифр, соответствующий псевдометкам классов, чтобы было красиво"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now visualize the learned representation with the class labels\n",
    "# посмотреть описание функций можно в их объявлении\n",
    "print('Наблюдения + количество раз, которое нейрон выигрывал')\n",
    "som.plot_point_map(data, targets, names, density=True, colors=colors)\n",
    "print('Количество раз, которое нейрон выигрывал')\n",
    "som.plot_density_map(data)\n",
    "print('Нормированные расстояния между нейронами')\n",
    "som.plot_distance_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сгруппируем данные по нейронам и создадим соответствующий словарь\n",
    "named_objects = []\n",
    "neuron_dict = {}\n",
    "for i in range(len(names)):\n",
    "    sample_data = data[i]\n",
    "    sample_name = names[i]\n",
    "    named_objects.append({'name': sample_name, 'data': sample_data})\n",
    "    winner_neuron = str(tuple([som.winner(sample_data)[1], som.winner(sample_data)[0]]))\n",
    "    if winner_neuron not in neuron_dict:\n",
    "        neuron_dict[winner_neuron] = [sample_name]\n",
    "    else:\n",
    "        neuron_dict[winner_neuron].append(sample_name)\n",
    "        \n",
    "# Создадим и упорядочим список с вхождениями словаря        \n",
    "data_list = []\n",
    "for k, v in neuron_dict.items():\n",
    "    data_list.append((k, v))\n",
    "\n",
    "sorted_data_list = list(sorted(data_list, key=lambda x: x[0]))\n",
    "for item in sorted_data_list:\n",
    "    # Выводи координаты нейрона-победителя и соотвествующие ему имена образцов данных\n",
    "    print(item)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
