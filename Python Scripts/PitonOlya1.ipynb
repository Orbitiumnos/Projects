{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1. Кластерный анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
    "from scipy.cluster import hierarchy\n",
    "\n",
    "%matplotlib inline \n",
    "# авто вывод графиков (отпадает необходимость писать plt.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Указываем названия признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['X20', 'X22', 'X29', 'X37', 'X38'] #список переменных\n",
    "f_len = len(features) #в переменную f_len записываем кол-во признаков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '11.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-79e211255c06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#считываем данные из data_lab1.xlsx (файл, который содержит все строки и выбранные признаки)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'11.xlsx'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# метод head() выводит первые 5 записей\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, **kwds)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     return io.parse(\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\pandas\\io\\excel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, io, **kwds)\u001b[0m\n\u001b[0;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_contents\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    393\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 394\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxlrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_workbook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_io\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    395\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    396\u001b[0m             raise ValueError('Must explicitly set engine if not passing in'\n",
      "\u001b[1;32mC:\\Programs\\Anaconda\\Anaconda\\lib\\site-packages\\xlrd\\__init__.py\u001b[0m in \u001b[0;36mopen_workbook\u001b[1;34m(filename, logfile, verbosity, use_mmap, file_contents, encoding_override, formatting_info, on_demand, ragged_rows)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile_contents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mpeek\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpeeksz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpeek\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34mb\"PK\\x03\\x04\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# a ZIP file\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '11.xlsx'"
     ]
    }
   ],
   "source": [
    "#считываем данные из data_lab1.xlsx (файл, который содержит все строки и выбранные признаки)\n",
    "data = pd.read_excel('11.xlsx',0)\n",
    "data.head() # метод head() выводит первые 5 записей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape #метод shape возвращает размерность матрицы объект-свойство"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стандартизируем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "index = data.index #записываем в переменную index названия строк исходной матрицы\n",
    "columns = data.columns #записываем в переменную columns названия столбцов исходной матрицы\n",
    "\n",
    "#стандартизируем данные: вычитаем среднее и делим на стандартное отклонение\n",
    "scaled = (data - data.mean(axis=0))/data.std() \n",
    "\n",
    "#создаем датафрейм из scaled со столбцами columns и индексами index\n",
    "scaled_data = pd.DataFrame(scaled, columns=columns, index=index) \n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Построение дендрограмм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "methods = ['complete', 'ward']\n",
    "q = [3,3]\n",
    "i = 0\n",
    "#для каждого из методов в methods проводим кластеризацию и строим дендрограмму\n",
    "for method in methods:\n",
    "    #проводим кластеризацию\n",
    "    Z = hierarchy.linkage(scaled_data, method=method)\n",
    "    \n",
    "    #строим дендрограмму \n",
    "    plt.figure(figsize=(10,6))\n",
    "    hierarchy.dendrogram(Z, color_threshold=q[i], labels=scaled_data.index, leaf_font_size=10)\n",
    "    plt.title('{} method'.format(method))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Оренбургский','г.Оренбург','г.Орск']\n",
    "#удаляем эти строки из исходного датафрейма\n",
    "data.drop(labels=labels, inplace=True)\n",
    "index = data.index\n",
    "\n",
    "#заново стандартизируем\n",
    "scaled = (data - data.mean(axis=0))/data.std()\n",
    "scaled_data = pd.DataFrame(scaled, columns=columns, index=index) \n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Если видим, что такое разбиение нас не устраивает (выброс образует целый кластер, например), то необходимо удалить выбросы и провести кластеризацию заново."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#заново смотрим дендрограммы, принимаем решение, на сколько кластеров делить\n",
    "methods = ['complete', 'ward']\n",
    "q = [4,7]\n",
    "i = 0\n",
    "#для каждого из методов в methods проводим кластеризацию и строим дендрограмму\n",
    "for method in methods:\n",
    "    #проводим кластеризацию\n",
    "    Z = hierarchy.linkage(scaled_data, method=method)\n",
    "    \n",
    "    #строим дендрограмму \n",
    "    plt.figure(figsize=(10,6))\n",
    "    hierarchy.dendrogram(Z, color_threshold=q[i], labels=scaled_data.index, leaf_font_size=10)\n",
    "    plt.title('{} method'.format(method))\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#если такое разбиение нас устраивает, продолжаем кластеризацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Проведение кластеризации тремя методами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Т.к. метод hierarchy.linkage не возвращает метки(номера) кластеров, то необходимо провести кластеризацию с помощью AgglomerativeClustering\n",
    "<br>\n",
    "<br>\n",
    "**n_clusters** - кол-во кластеров, которое мы выбираем самомтоятельно\n",
    "<br>\n",
    "**linkage** - выбранные метод"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_METHODS = [\"complete\", \"ward\", \"kmeans\"]\n",
    "\n",
    "#для каждого из методов выбрать кол-во кластеров \n",
    "N_CLUSTERS = {\n",
    "    \"complete\" : 3,\n",
    "    \"ward\"     : 3,\n",
    "    \"kmeans\"  : 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#проводим кластеризацию методом полных связей\n",
    "\n",
    "# создаем объект класса AgglomerativeClustering, указываем для этого объекта значения параметров\n",
    "# т.е. n_clusters - кол-во кластеров, linkage - метод кластеризации\n",
    "# называем созданный объект complete\n",
    "\n",
    "complete = AgglomerativeClustering(n_clusters=N_CLUSTERS['complete'], linkage='complete')\n",
    "\n",
    "#методы, которые можно указывать в linkage: “ward”, “complete”, “average”\n",
    "\n",
    "# с помощью метода .fit \"настраиваем\" объект под наши данные, \n",
    "# т.е. проводим кластеризацию наших данных с параметрами, которые мы указали при создании complete \n",
    "complete.fit(scaled_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#проводим кластеризацию методом Уорда\n",
    "ward = AgglomerativeClustering(n_clusters=N_CLUSTERS['ward'], linkage='ward')\n",
    "ward.fit(scaled_data);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проведения кластеризации методом K-means необходимо воспользоваться KMeans из sklearn.cluster\n",
    "<br>\n",
    "<br>\n",
    "**random_state** - параметр, принимающий любое числовое значение. Необходим для воспроизведения результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#проводим кластеризацию методом K-means\n",
    "kmeans = KMeans(n_clusters=N_CLUSTERS['kmeans'], random_state=17)\n",
    "kmeans.fit(scaled_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data['complete'] = complete.labels_\n",
    "scaled_data['ward'] = ward.labels_\n",
    "scaled_data['kmeans'] = kmeans.labels_\n",
    "scaled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для каждого из созданных шагом ранее объектов с помощью атрибута **.labels_** можно получить метки кластеров для каждой из проведенных кластеризаций.\n",
    "<br>\n",
    "**complete.labels_** - для метода полных связей\n",
    "<br>\n",
    "**ward.labels_** - для метода Уорда\n",
    "<br>\n",
    "**kmeans.labels_** - для K-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Работа с метками кластеров. Построение графиков средних значений для каждого кластера по каждому признаку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ниже объявлена функция, которая возвращает список из средних по каждому столбцу.\n",
    "#т.е. она формирует массив из средних для метода method c кол-вом кластеров n_clust\n",
    "\n",
    "def mean_df(method, n_clust):\n",
    "    mean_data = np.array([]).reshape(0, f_len+1)\n",
    "    for n in range(n_clust): #номер кластера\n",
    "        tmp = [] #список для средних по каждому признаку\n",
    "        for j in range(f_len):\n",
    "            tmp.append(scaled_data[scaled_data[method] == n].iloc[:, j].mean())\n",
    "        tmp.append(scaled_data[scaled_data[method] == n].shape[0])\n",
    "        mean_data = np.vstack((mean_data, np.array(tmp).reshape(1, f_len+1)))\n",
    "    return mean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Формируем датафрейм из средних значений для каждого кластера по каждому признаку с использованием функции mean_df, описанный выше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = features + ['count']\n",
    "\n",
    "# Создаем словарь из списком по имени means, в котором имена ключей будут Имя_Метода,\n",
    "# а каждому ключу будет соответствовать датафрейм из средних значений по каждому кластеру\n",
    "\n",
    "means = {}\n",
    "dfs = []\n",
    "\n",
    "path = \"means.xlsx\" # создаем переменную path, которой присваиваем название файла для записи средних\n",
    "writer = pd.ExcelWriter(path) # вызываем метод ExcelWriter библиотеки pandas \n",
    "\n",
    "\n",
    "for method, n in N_CLUSTERS.items():\n",
    "    #Заполняем словарь\n",
    "    means[method] = pd.DataFrame(\n",
    "        mean_df(method, n), #ищем среднее значение признаков с помощью функции mean_df\n",
    "        columns=columns, \n",
    "        index=[\"{}_{}\".format(method, i) for i in range(n)]\n",
    "    )\n",
    "\n",
    "    #запись средних значений в в файл means на разные листв\n",
    "    #файл создается в той же директории, где лежит ноутбук с кодом\n",
    "    means[method].to_excel(writer, sheet_name = '{} means'.format(method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Получился словарь means с ключами 'complete', 'ward', 'kmeans'\n",
    "#Каждому ключу соответствует датафрейм из 6 столбцов и стольких строк, \n",
    "#сколько кластеров в данном конкретном методе\n",
    "\n",
    "mean_data = pd.DataFrame()\n",
    "for method in CLUSTER_METHODS:\n",
    "    mean_data = mean_data.append(means[method])\n",
    "mean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#строим графики средних значений признаков по каждому кластеру\n",
    "\n",
    "#цикл выполняется для каждого элемента из списка CLUSTER_METHODS т.е. для 'complete', 'ward', 'kmeans'\n",
    "for method in CLUSTER_METHODS:\n",
    "    # в cur_mean записываются средние для текущего метода (по которому проходим на данной итерации цикла)\n",
    "    cur_mean = means[method] \n",
    "    plt.figure(figsize=(6,4)) #формируем область для построения графиков под каждый из методов\n",
    "    for n in range(cur_mean.shape[0]): #для каждого кластера из данного метода\n",
    "        \n",
    "        #plt.plot - для каждого кластера из данного метода строится обычный линейный график, где \n",
    "        #x=features (т.е. названия признаков) \n",
    "        #y=cur_mean.iloc[n, :-1] - т.е. n-ая строка средних \n",
    "        #(n - номер кластера, для которого на данной итерации цикла строим график) \n",
    "        #берем строку без последнего столбца (там count лежит, он нам не нужен), т.е. пишем \":-1\" в методе iloc\n",
    "        \n",
    "        plt.plot(features, cur_mean.iloc[n, :-1].values, marker='o', label='cluster {}'.format(n))\n",
    "    plt.legend(loc = 'upper left') #делаем легенду графиа\n",
    "    plt.title('{} method'.format(cur_mean.index[0][:-2])) #название графика"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим словарь cluster_dict из списков, в котором ключами будут **Название Метода__Номер Кластера**\n",
    "<br>\n",
    "<br>\n",
    "Например, **complete_0** - элемент словаря, по которому можно получить строки, соответствующие кластеру 0 для метода полных связей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = {}\n",
    "\n",
    "\n",
    "path = \"members.xlsx\" # создаем переменную path, которой присваиваем название файла для записи объектов кластеров\n",
    "writer = pd.ExcelWriter(path) # вызываем метод ExcelWriter библиотеки pandas \n",
    "\n",
    "for method, n in N_CLUSTERS.items():\n",
    "    print('{} method\\n'.format(method)) # выводим заголовки методов по шаблону \n",
    "    dfs = []  \n",
    "    for i in range(n): # для каждого кластера проходимся по объектам и записываем их в словарь \n",
    "        cluster_dict['{}_{}'.format(method, i)] = \\\n",
    "           scaled_data[scaled_data[method]==i][features]\n",
    "        \n",
    "        #запись членов кластеров в файл members на лист с именем Метод_НомерКластера\n",
    "        #файл создается в той же директории, где лежит ноутбук с кодом\n",
    "        cluster_dict['{}_{}'.format(method, i)]\\\n",
    "        .to_excel(writer, sheet_name = '{}_{}'.format(method, i))\n",
    "        \n",
    "        print ('Состав кластера {}: {}'\n",
    "              .format(i, cluster_dict['{}_{}'.format(method, i)].index.values))      \n",
    "    print ('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Функционал ошибки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Q(method_num, mean_data_row):\n",
    "    q = 0 # Обнуляем функционал качества разбиения \n",
    "    for i in range(len(method_num)): # проходимся по каждому элементу кластера\n",
    "        \n",
    "        # Во временную переменную записываем промежуточные значения суммы, чтобы потом добавлять их к Q\n",
    "        tmp = 0\n",
    "        for j, feature in zip(range(len(features)), features):\n",
    "            \n",
    "            #проходя по каждому признаку, считаем сумму квадратов расстояний от значения объекта до центра кластера\n",
    "            tmp = tmp + (method_num.iloc[i, j] - mean_data_row[feature][0])**2 \n",
    "            \n",
    "            # Прибавляем к Q\n",
    "        q = q + tmp\n",
    "    #возвращаем конечную сумму\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#создаем пустой словарь, в который будем записывать значения функционалов ошибки для каждого метода\n",
    "Q_dict = {}\n",
    "\n",
    "#k - номер строки в датафрейме mean_data (выведен выше)\n",
    "k = 0\n",
    "\n",
    "for method, n in N_CLUSTERS.items():\n",
    "    #временная переменная, нужна для суммирования функционала ошибки для каждого кластера в рамках одного метода\n",
    "    tmp = 0\n",
    "    #для каждого кластера (их всего n) в данном методе method выполняются действия в теле цикла\n",
    "    for i in range(n):\n",
    "        #в переменную tmp прибавляется значение Q для текущего номера кластера i (изменяется от 0 до n-1)\n",
    "        #в Q передаем в качестве первого аргумента - датафрейм, содержащий члены текущего кластера\n",
    "        #в качестве второго аргумента - строку из mean_data с индексом k (там записаны средние значения для данного кластера i)\n",
    "        tmp += Q(cluster_dict['{}_{}'.format(method, i)], pd.DataFrame(mean_data.iloc[k]).T)\n",
    "        #увеличиваем k на 1 (чтобы перейти к следующей строке mean_data)\n",
    "        k += 1   \n",
    "    #после того, как прошли по всем кластерам в рамках метода method и просуммировали функционалы ошибки в переменной tmp, запишем результирующую сумму в словарь\n",
    "    Q_dict['Q_{}'.format(method)] = round(tmp, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
